{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/02\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/wesmail/Panda/spark-2.2.1-bin-hadoop2.7\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder  \\\n",
    ".master(\"local[2]\")  \\\n",
    ".appName(\"Linear Regrssion Model\")  \\\n",
    ".config(\"spark.executor.memory\",\"8gb\")  \\\n",
    ".getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# LOAD HERE\n",
    "from root_numpy import root2array, tree2array, rec2array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "branch_names = \"\"\"momentum,energy,position,MvdDEDX,MvdHits,SttMeanDEDX,SttHits,GemHits,TofStopTime,\n",
    "TofM2,TofTrackLength,TofQuality,TofBeta,DrcThetaC,DrcThetaCErr,DrcQuality,DrcNumberOfPhotons,\n",
    "DiscThetaC,DiscQuality,DiscNumberOfPhotons,\n",
    "RichThetaC,RichQuality,RichNumberOfPhotons,\n",
    "EmcRawEnergy,EmcCalEnergy,EmcQuality,EmcNumberOfCrystals,EmcNumberOfBumps,EmcModule,\n",
    "EmcZ20,EmcZ53,EmcLat,EmcE1,EmcE9,EmcE25,MuoProbability,MuoQuality,MuoIron,MuoMomentumIn,MuoNumberOfLayers,MuoModule,MuoHits,\n",
    "DegreesOfFreedom,FitStatus,ChiSquared\"\"\".split(\",\")\n",
    "branch_names = [c.strip() for c in branch_names]\n",
    "branch_names = list(branch_names)\n",
    "\n",
    "electrons = root2array(\"/home/wesmail/Downloads/treeElectrons.root\", \"t1\", branch_names)\n",
    "electrons = rec2array(electrons)\n",
    "\n",
    "pions = root2array(\"/home/wesmail/Downloads/treePions.root\", \"t1\", branch_names)\n",
    "pions = rec2array(pions)\n",
    "\n",
    "muons = root2array(\"/home/wesmail/Downloads/treeMuons.root\", \"t1\", branch_names)\n",
    "muons = rec2array(muons)\n",
    "\n",
    "kaons = root2array(\"/home/wesmail/Downloads/treeKaons.root\", \"t1\", branch_names)\n",
    "kaons = rec2array(kaons)\n",
    "\n",
    "anti_p = root2array(\"/home/wesmail/Downloads/treeProtons.root\", \"t1\", branch_names)\n",
    "anti_p = rec2array(anti_p)\n",
    "\n",
    "X = np.concatenate((electrons, pions, muons, kaons, anti_p))\n",
    "y = np.concatenate(( np.zeros(electrons.shape[0]), (np.ones(pions.shape[0])), (2*np.ones(muons.shape[0])), (3*np.ones(kaons.shape[0])), (4*np.ones(anti_p.shape[0])) ))\n",
    "\n",
    "# Create DataFrame from X and y\n",
    "df = pd.DataFrame(np.hstack((X, y.reshape(y.shape[0], -1))),columns=branch_names+['label'])\n",
    "\n",
    "# Create Spark DataFrame\n",
    "sparkRDD = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the branches into feature coloumn\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=branch_names,outputCol=\"features\")\n",
    "data = assembler.transform(sparkRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3], seed=0)\n",
    "\n",
    "\n",
    "# Train a RandomForest model.\n",
    "dt = RandomForestClassifier(labelCol='label', featuresCol='features', numTrees=20,  maxDepth=15)\n",
    "\n",
    "# Fit model.\n",
    "model = dt.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictionAndLabels = predictions.select(\"prediction\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[72] at javaToPython at NativeMethodAccessorImpl.java:0\n",
      "[[9987.  123.   65.   73.   59.]\n",
      " [ 205. 7501. 1138.  892.  376.]\n",
      " [ 124.  807. 9242.  210.   27.]\n",
      " [ 117. 1093.  408. 7179.  987.]\n",
      " [ 118.  275.  108. 1044. 7984.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(113.922,0.5,u'true value')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'predictionAndLabels' into spark RDD\n",
    "mypred = predictionAndLabels.rdd\n",
    "print (mypred)\n",
    "\n",
    "# Evaluation metrics\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "metrics = MulticlassMetrics(mypred)\n",
    "\n",
    "# Build the confusion matrix\n",
    "cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "# Show the confusion matrix\n",
    "print (cm)\n",
    "\n",
    "# Normalize and plot the confusion matrix (Rows = True values, Coloumns = Predicted Values)\n",
    "# normalized over coloumns (axis=1)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "figcm, ax = plt.subplots()\n",
    "cm = cm.astype('float') / cm.sum(axis=1)\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(cm, square=True, annot=True, cbar=False)\n",
    "classes=['e-','pi-', 'mu-', 'k-', 'p-']    # 0 1 2 3 4 \n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=90)\n",
    "ax.set_xticks(np.arange(len(classes))+0.5, minor=False)\n",
    "plt.yticks(tick_marks, classes)\n",
    "ax.set_yticks(np.arange(len(classes))+0.5, minor=False)\n",
    "plt.xlabel('predication', horizontalalignment = 'center')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
